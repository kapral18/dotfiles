{
  "$schema": "https://opencode.ai/config.json",
  "small_model": "openrouter/minimax/minimax-m2.1",
  "theme": "catppuccin",
  "share": "disabled",
  "autoupdate": false,
  "permission": {
    "edit": "allow",
    "bash": "allow",
    "webfetch": "allow",
    "skill": "allow",
    "external_directory": "allow",
    "doom_loop": "ask",
  },
  "agent": {
    "plan": {
      "disable": true,
    },
    "build": {
      "disable": true,
    },
    "explore": {
      "disable": true,
    },
    "general": {
      "disable": true,
    },
    "main": {
      "description": "Main workflow agent. Can invoke sub-agents as needed to minimize token use.",
      "mode": "primary",
      "model": "openrouter/openai/gpt-5.2",
      "reasoning_effort": "high",
    },
    "worker_a": {
      "description": "Implements tasks and reports concise results back to main agent",
      "mode": "subagent",
      "model": "openrouter/minimax/minimax-m2.1",
    },
    "worker_b": {
      "description": "Second implementer for parallel work, reports concise results back to main agent",
      "mode": "subagent",
      "model": "openrouter/minimax/minimax-m2.1",
    },
    "worker_c": {
      "description": "Third implementer for parallel work, reports concise results back to main agent",
      "mode": "subagent",
      "model": "openrouter/minimax/minimax-m2.1",
    },
    "worker_d": {
      "description": "Fourth implementer for parallel work, reports concise results back to main agent",
      "mode": "subagent",
      "model": "openrouter/minimax/minimax-m2.1",
    },
  },
  "default_agent": "orchestrator",
  "mcp": {
    "playwright": {
      "type": "local",
      "command": ["npx", "-y", "@playwright/mcp@latest"],
      "enabled": true,
    },
    "sequential-thinking": {
      "type": "local",
      "command": [
        "npx",
        "-y",
        "@modelcontextprotocol/server-sequential-thinking",
      ],
      "enabled": true,
    },
    "scsi-main": {
      "type": "local",
      "command": [
        "bash",
        "-lc",
        "docker run --pull=always --rm -i -e ELASTICSEARCH_CLOUD_ID=\"$(pass scsi/simian/cloud_id)\" -e ELASTICSEARCH_API_KEY=\"$(pass scsi/simian/api_key)\" -e ELASTICSEARCH_INDEX=kibana-repo simianhacker/semantic-code-search-mcp-server node dist/src/mcp_server/bin.js stdio",
      ],
      "enabled": true,
    },
    "scsi-local": {
      "type": "local",
      "command": [
        "bash",
        "-lc",
        "docker run --pull=always --rm -i -e ELASTICSEARCH_CLOUD_ID=\"$(pass scsi/k18/cloud_id)\" -e ELASTICSEARCH_API_KEY=\"$(pass scsi/k18/api_key)\" -e ELASTICSEARCH_INDEX=scsi-repo simianhacker/semantic-code-search-mcp-server node dist/src/mcp_server/bin.js stdio",
      ],
      "enabled": true,
    },
    "exa": {
      "type": "remote",
      "url": "https://mcp.exa.ai/mcp",
    },
  },
}
